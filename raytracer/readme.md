# Raytracer

Реализация игрушечного рейтрейсера, с помощью которого можно
рендерить простейшие сцены.

### Освещение

Освещенность в точке $`p`$ некоторого объекта задается формулой
```math
I_p = I_{base}(p) + I_{comp}(p),
```

где
```math
I_{base}(p) = K_a + K_e + \sum_{m \in lights} (K_d I_d(p, m) + K_s I_s(p, m))
```

Сумма берется по всем источникам света, которые видны из точки $`p`$ (все объекты считаются непрозрачными при проверке на видимость). $`I_d`$ и $`I_s`$
это соответственно diffuse и specular составляющие освещения из модели Фонга (https://en.wikipedia.org/wiki/Phong_reflection_model).

$`I_{comp}`$ вычисляется только в том случае, если для заданного объекта нужно считать отраженный и преломленный лучи (это будет задаваться
в свойствах материалов), и в этом случае эта величина считается так:
```math
I_{comp}(p) = (1.0 - d)I_{refract}(p) + K_d I_d(p, I_{reflect}(p)) + K_s I_s(p, I_{reflect}(p))
```

Здесь $`d`$ - степень непрозрачности объекта, $`I_{refract}(p)`$ - освещенность от преломленного в точке $`p`$ луча, а $`I_{reflect}(p)`$ - освещенность
отраженного в $`p`$ луча. Обратите внимание, что отраженный луч не нужно считать, если сейчас трассируются
луч внутри объекта (в нашем случае если трассируется преломленный луч внутри полупрозрачной сферы).

### Постпроцессинг

#### Tone Mapping

Когда рендеринг завершен, и для каждой точки известна тройка `v = (r, g, b)`, нужно произвести ряд действий.
Основная проблема состоит в том, что эти значения могут быть больше 1, а чтобы сохранить изображение нужно иметь значения в диапазоне `[0,1]`.
Процедура приведения этих значений в диапазон `[0,1]` обычно называется [tone mapping](https://en.wikipedia.org/wiki/Tone_mapping), и в нашем задании ее нужно сделать следующим
образом:

* Пусть наибольшее значение среди всех `(r, g, b)` по всем точкам изображения равно `C` (это скаляр, т.е. максимум берется и по самим тройкам).
* Тогда вектор $`V_{in} = (r, g, b)`$ нужно преобразовать в выходной $`V_{out}`$ по правилу (все операции выполняются поэлементно)
```math
V_{out} = \dfrac{V_{in}\left(1 + \dfrac{V_{in}}{C^2}\right)}{1 + V_{in}}
```

#### Гамма коррекция

Теперь когда все значения лежат в диапазоне `[0,1]` осталось сделать последний шаг. Все вычисления при рендеринге выполнялись в линейном RGB,
но при сохранении изображений линейный RGB практически никогда не используется, т.к. в этом случае нужно выделять больше 8 бит на канал (например
иметь значения в диапазоне `[0, 2^16)`), чтобы изображение выглядело нормально. Пусть значение $`V_{out}`$ получено с предыдущего шага.
Тогда в итоговое изображение нужно записать
```math
V_{gamma} = V_{out}^{\frac{1}{2.2}}
```

Обратите внимание, что класс `Image`, через который происходит запись изображений, ожидает целочисленные rgb, т.е. полученное $`V_{gamma}`$ нужно
домножить на 255 и привести в целые числа.

Подробнее можно прочитать на вики (https://en.wikipedia.org/wiki/Gamma_correction) если интересно.

### Формат .obj файлов

Описание формата можно посмотреть на вики: https://en.wikipedia.org/wiki/Wavefront_.obj_file. 